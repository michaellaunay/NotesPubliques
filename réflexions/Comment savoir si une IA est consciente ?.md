En raison des progrès rapides du domaine de l'IA, savoir si un dispositif technique pourrait être conscient devient urgent. D'autant que le test de Turing ne semble pas suffisant à le déterminer.

C'est dans ce contexte que plusieurs experts, comme Ilya Sutskever (ex-scientifique en chef d’OpenAI), ont suggéré que des modèles avancés pourraient être légèrement "conscients". Mais pour la communauté scientifique, cette affirmation soulève une question essentielle : comment évaluer objectivement la conscience d’un système d’IA ?

Un collectif de 19 chercheurs (neuroscientifiques, philosophes, informaticiens), dont le pionnier de l’IA Yoshua Bengio, a proposé un guide préliminaire pour répondre à cette question. Leur objectif est de fournir une base empirique et théorique solide pour détecter une éventuelle conscience dans les systèmes d’IA, à partir d’un croisement entre les neurosciences et les sciences cognitives.

Identifier la conscience dans une IA aurait des implications morales majeures. Une entité consciente ne devrait pas être traitée comme une simple machine. Pourtant, peu d’entreprises technologiques (Google, Microsoft, etc.) se penchent sur la question (c.f. Blake Lemoine).

Mais quelle définition de la conscience utiliser ?

Ici les chercheurs se concentrent sur la conscience phénoménale, c’est-à-dire l’expérience subjective, le ressenti d’être.

Les théories retenues :
Il n’existe pas de consensus scientifique sur la théorie unique expliquant la conscience. Le groupe s’est donc appuyé sur six théories neurocognitives reconnues, en extrayant des indicateurs clés compatibles avec le fonctionnalisme computationnel (l’idée que la conscience dépend du traitement de l'information, pas du support biologique).

L’une des plus importantes est la théorie de l’espace de travail global, selon laquelle la conscience émerge d’un système intégrant les informations issues de différents modules spécialisés (vision, mémoire, etc.). Un système d’IA structuré de cette façon, avec une circulation d’informations centralisée et consciente, pourrait donc manifester certains signes de conscience.

À l’inverse, la théorie de l'information intégrée (IIT) a été écartée, car elle suppose que seuls les supports biologiques peuvent donner lieu à la conscience – ce qui exclut les IA basées sur des circuits numériques.

Application et limites
Le guide est provisoire, et les auteurs espèrent qu’il sera enrichi par d'autres chercheurs. Mais il peut déjà s’appliquer à des modèles actuels comme ChatGPT, dont certaines propriétés semblent compatibles avec la théorie de l’espace de travail global.

Cependant, aucun système actuel n’est considéré comme proche d’un seuil de conscience, même si certaines architectures s’en rapprochent sur le papier.

https://www.pourlascience.fr/sd/informatique/comment-savoir-si-une-ia-est-consciente-27543.php